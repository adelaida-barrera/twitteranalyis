---
title: "Topic_models"
author: "Adelaida Barrera"
date: "12/8/2020"
output: html_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(quanteda)
library(readtext) # for getting document and their info into a data frame 
library(stm) # for modeling topics
library(tm)
library(tidytext) #to work with output from models more easily (tidy framework)
```


```{r}

# Load sample from feminists dfm 
load("data/Sample_quanteda.RData")

```

```{r}

stm_sample_fem <- asSTMCorpus(sample_quanteda)

summary(stm_sample_fem)

out <- prepDocuments(stm_sample_fem$documents, 
                     stm_sample_fem$vocab, 
                     stm_sample_fem$meta)

model_15_topics <- stm(documents = out$documents, 
              vocab = out$vocab, 
              K = 15, seed = 12345)

save(model_15_topics, file = "data/15topics_sample_n23000")



```

```{r}

library(stm)
load("data/15topics_sample_n23000") 

# See what the model picked up

# Most probable words in each topic
summary(model_15_topics)

#
plot(model_15_topics, type = "labels", labeltype = "prob", topics = (1:3)) # or frex, lift, score
plot(model_15_topics, type = "labels", labeltype = "prob", topics = (3:6)) 
plot(model_15_topics, type = "labels", labeltype = "prob", topics = (7:9)) 
plot(model_15_topics, type = "labels", labeltype = "prob", topics = (10:12)) 

plot(model_15_topics, type = "labels", labeltype = "prob", topics = (10:12)) 

#Seeing some documents from each topic 

#Getting a sample of documents from the corpus of the same size as the sample taken from the dfm 
sample_docs <- corpus_sample(x = feminists_corp, size = 21699)

findThoughts(model_15_topics, texts = texts(sample_docs), topics = (1:15),n = 5) # doesnt make full sense.


```

```{r}

# 

tidy_model <- tidy(model_15_topics)

tidy_model %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    mutate(topic = paste0("Topic ", topic),
           term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(term, beta, fill = as.factor(topic))) +
    geom_col(alpha = 0.8, show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free_y", nrow = 2) +
    coord_flip() +
    scale_x_reordered() +
    labs(x = NULL, y = expression(beta),
         title = "Highest word probabilities for each topic",
         subtitle = "Different words are associated with different topics")


```

