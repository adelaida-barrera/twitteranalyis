---
title: "Topic models plots"
author: "Adelaida Barrera, Isabel de Brigard, Natalia Mej√≠a, Mariana Saldarriaga"
date: "12/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggplot2)
library(tidytext)
library(kableExtra)
library(knitr)
library(lubridate)
```

```{r}

# Loading the output objects from the topic models and the dfm's 

# Individual 

#DFM used for topic model 
load("data/non_congress_dfm_full")

# Topic Model 
load("model_topics_full")

#Dataframe with tweets and metadata (object name is "non_congres")
load("data/non_congress_fem_jul_nov_2020.RData")

# Institutional 

# DFM used for topic model 
load("data/full_institutions_dfm.Rdata")

# Topic Model 
load("model_topics_inst_full")

#Dataframe with tweets and metadata (object name is "inst_jul_nov_2020")
load("data/inst_jul_nov_2020.RData")

```

The LDA model calculates the probability of each word being generated from each topic (betas) and the 'per-document-per-topic probabilities': the proportion of words from that document that are generated from each topic. 

We can broadly identify what the 10 topics are for both the individual and the institutional accounts, although the model does not perfectly classify the documents according to our posterior interpretation. 

Topics in individual accounts:

* Topic 1: Media & equality 
* Topic 2: Public opinion
* Topic 3: State violence 
* Topic 4: Human rights, women's rights
* Topic 5: Sexual violence, gender violence 
* Topic 6: National politics 
* Topic 7: Journalism  
* Topic 8: Political violence 
* Topic 9: Everyday life & feminism
* Topic 10: Judicial  

Topics in institutional accounts: 

# Most common words in each topic 

```{r}
# options(repr.plot.width = 30, repr.plot.height = 15)

# Individual

colors <- c("#E63D3D",#red 
            "#694DE6", #purple 
            "#196CFF", #blue
            "#3EA3B3", #aqua
            "#72C22B", #green
            "#4E9435",#green
            "#D4159F", #pink
            "#F59824", #orange
            "#631257", #burgundy
            "#717174") #grey
           
# Topic lables for individual accounts 
topic_labels <- c("Media & equality", "Public opinion", "State violence", "Women's rights", "Gender violence", "National politics", "Journalism", "Political violence", "Everyday life", "Judicial")
```

```{r}

# Get a tidy df from the topic model to use the 'betas'
model_betas <- tidy(model_topics_non_congress, matrix = "beta")


#Identify the words that are most common within topics
model_top_terms <- model_betas %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta) %>% 
  mutate(topic = factor(topic, 
                        levels = 1:10, 
                        labels = topic_labels))

# Plot 

frequent_words_ind <- model_top_terms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  labs(x = "\n Word probabilities per topic (betas)",
       y = "Term \n", 
       title = "Ten most common terms in each topic (individual accounts)") +
  scale_y_reordered() +
  scale_x_continuous(n.breaks = 2) +
  scale_fill_manual(values = colors) +
  theme_minimal() +
  theme(text = element_text(size = 9))

# Save plot for report  
ggsave(frequent_words_ind, file = "figures/5_frequent_words_ind.png")
```

```{r}

# Institutional 

# Topic lables for institucional accounts 

topic_labels_i <- c("Violence",
                    "Pandemic & LGBT",
                    "Social policy",
                    "Intitutions' work", 
                    "Institutional events", 
                    "Armed conflict",
                    "Gender & diversity",
                    "Women",
                    "Truth comission",
                    "Reproductive rights")

# Get tidy object 
model_betas <- tidy(model_topics_institutions_full, matrix = "beta")

# Get most likely words
model_top_terms <- model_betas %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta) %>% 
  mutate(topic = factor(topic, 
                        levels = 1:10, 
                        labels = topic_labels_i))


# Plot 

frequent_words_ins <- model_top_terms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  labs(x = "\n Word probabilities per topic (betas)",
       y = "Term \n", 
       title = "Ten most common terms within each topic (institutional accounts)") +
  scale_y_reordered() +
  scale_x_continuous(n.breaks = 2) +
  scale_fill_manual(values = colors) +
  theme_minimal() +
  theme(text = element_text(size = 9))
  
frequent_words_ins

# Save to include in report 

ggsave(frequent_words_ins, file = "figures/6_frequent_words_ins.png")

```

# Proportion of topics in corpus 

## Individual accounts 
```{r}

#Gather the betas and gammas from the topic model into dataframes in order to work with the tidyverse framework 

td_beta <- tidy(model_topics_non_congress)

td_gamma <- tidy(model_topics_non_congress, matrix = "gamma",
                 document_names = rownames(non_congress_dfm_full))
```

```{r}

# Get the top 12 most likely words to be generated when talking about each topic.

top_terms <- td_beta %>%
  arrange(beta) %>%
  group_by(topic) %>%
  top_n(12, beta) %>%
  arrange(-beta) %>%
  select(topic, term) %>%
  summarise(terms = list(term)) %>%
  mutate(terms = map(terms, paste, collapse = ", ")) %>% 
  unnest()

# Get the mean proportion of each topic across all documents in descending order
gamma_terms <- td_gamma %>%
  group_by(topic) %>%
  summarise(gamma = mean(gamma)) %>%
  arrange(desc(gamma)) %>%
  left_join(top_terms, by = "topic") %>%
  arrange(topic) %>% 
  mutate(topic = topic_labels,
         topic = reorder(topic, gamma))

topics_ind_plot <- gamma_terms %>%
  top_n(20, gamma) %>%
  ggplot(aes(topic, gamma, 
             label = terms, 
             fill = topic)) +
  geom_col(show.legend = FALSE) +
  geom_text(hjust = 0.2, nudge_y = 0.0005, size = 2.5) +
  coord_flip() +
  theme_minimal() +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0, 0.3)) +
  scale_fill_manual(values = c(colors)) +
  labs(x = NULL, y = expression(gamma),
       title = "Most frequent topics in the individual feminists' accounts",
       subtitle = "Top words that contribute to each topic")

topics_ind_plot

ggsave(topics_ind_plot, file = "figures/7_prevalence_topics_ind.png")
```

## Institutional accounts 

```{r}


#Gather the betas and gammas from the topic model into dataframes in order to work with the tidyverse framework 

td_beta_ins <- tidy(model_topics_institutions_full)

td_gamma_ins <- tidy(model_topics_institutions_full, matrix = "gamma",
                 document_names = rownames(institutions_dfm_full))

# Get the top 12 most likely words to be generated when talking about each topic.

top_terms_ins <- td_beta_ins %>%
  arrange(beta) %>%
  group_by(topic) %>%
  top_n(12, beta) %>%
  arrange(-beta) %>%
  select(topic, term) %>%
  summarise(terms = list(term)) %>%
  mutate(terms = map(terms, paste, collapse = ", ")) %>% 
  unnest()

# Get the mean proportion of each topic across all documents in descending order
gamma_terms_ins <- td_gamma_ins %>%
  group_by(topic) %>%
  summarise(gamma = mean(gamma)) %>%
  arrange(desc(gamma)) %>%
  left_join(top_terms_ins, by = "topic") %>%
  arrange(topic) %>% 
  mutate(topic = topic_labels_i,
         topic = reorder(topic, gamma))

topics_ins_plot <- gamma_terms_ins %>%
  top_n(20, gamma) %>%
  ggplot(aes(topic, gamma, 
             label = terms, 
             fill = topic)) +
  geom_col(show.legend = FALSE) +
  geom_text(hjust = 0.2, nudge_y = 0.0005, size = 2.5) +
  coord_flip() +
  theme_minimal() +
  scale_y_continuous(expand = c(0,0),
                     limits = c(0, 0.3)) +
  scale_fill_manual(values = c(colors)) +
  labs(x = NULL, y = expression(gamma),
       title = "Topics by prevalence in institutional twitter discourse on gender",
       subtitle = "Top words that contribute to each topic")

topics_ins_plot



```

# Topic proportions across time 

### Individual 
```{r}

tweets_meta <- non_congress %>% 
  select(id, 
         text_id, 
         screen_name,
         text,
         favorite_count,
         retweet_count,
         day_published,
         name, 
         main_occupation,
         institution) %>% 
  rename(document = text_id) %>% 
  mutate(week_published = week(day_published))

gammas <- tidy(model_topics_non_congress, matrix = "gamma",
                 document_names = rownames(non_congress_dfm_full))


#Geting only the most predominant topic per document 

main_gammas <- gammas %>% 
  group_by(document) %>%
  filter(gamma == max(gamma)) %>%
  ungroup() %>%
  arrange(document)

# Joining tidy model main topics with tweetr dataframe

non_congress_wgammas <- left_join(main_gammas, tweets_meta, by = "document")

```

### Plotting

```{r}

weekly_topics <- 
  non_congress_wgammas %>% 
  group_by(week_published, topic) %>% 
  summarize(n_docs_per_topic_in_week = n())

docs_per_week <- non_congress_wgammas %>% group_by(week_published) %>% summarise(n_doc_week = n())

weekly_topics <-
  inner_join(weekly_topics, docs_per_week) %>% 
  mutate(proportion_topic_week = n_docs_per_topic_in_week / n_doc_week,
         topic = topic_labels,
         date = as_date(duration(week_published,units = "weeks"),
                        origin = "2020-01-01"))
  
# Plotting all topics at once 
weekly_topics %>%  
  ggplot(aes(x = date,
           y = proportion_topic_week,
           color = factor(topic))) +
  geom_line(alpha = 0.5, size = 0.6) + 
  geom_point() + 
  theme_minimal()+
  labs(title = "Proportion of documents from each topic by week (2020)",
       x = "\n Week published",
       y = "Proportion of documents \n") +
   scale_color_manual(values = c(colors),
                     name = "Topic")



# Closer look at the dynamic between women's rights discourse and national politics  

weekly_topics %>%
  filter(topic %in% c("Women's rights",
                      "National politics")) %>%  
  ggplot(aes(x = date,
             y = proportion_topic_week,
             color = factor(topic))) +
  geom_line(alpha = 0.5, size = 0.6) + 
  geom_point() + 
  theme_minimal()+
  labs(title = "Proportion of documents from each topic by week (2020)",
        x = "\n Week published",
        y = "Proportion of documents \n") +
  scale_color_manual(values = c(colors),
                     name = "Topic")

```

### Institutional 
```{r}

tweets_meta_ins <- inst_jul_nov_2020 %>% 
  select(id, 
         text_id, 
         screen_name,
         text,
         favorite_count,
         retweet_count,
         day_published) %>% 
  rename(document = text_id) %>% 
  mutate(week_published = week(day_published))

gammas_ins <- tidy(model_topics_institutions_full, matrix = "gamma",
                 document_names = rownames(institutions_dfm_full))

#Geting only the most predominant topic per document 

main_gammas_ins <- gammas_ins %>% 
  group_by(document) %>%
  filter(gamma == max(gamma)) %>%
  ungroup() %>%
  arrange(document)

# Joining tidy model main topics with tweetr dataframe

institutions_wgammas <- left_join(main_gammas_ins, tweets_meta_ins, by = "document")

```

```{r}

# Plotting

weekly_topics_ins <- 
  institutions_wgammas %>% 
  group_by(week_published, topic) %>% 
  summarize(n_docs_per_topic_in_week = n())

docs_per_week_ins <- institutions_wgammas %>% group_by(week_published) %>% summarise(n_doc_week = n())

weekly_topics_ins <-
  inner_join(weekly_topics_ins, docs_per_week_ins) %>% 
  mutate(proportion_topic_week = n_docs_per_topic_in_week / n_doc_week,
         date = as_date(duration(week_published,
                                 units = "weeks"),
                        origin = "2020-01-01"),
         topic = case_when(
           topic == 1 ~ "Service provision",
           topic == 2 ~ "Peace agreement",
           topic == 3 ~ "Women",
           topic == 4 ~ "National issues",
           topic == 5 ~ "Gender violence",
           topic == 6 ~ "Human Rights",
           topic == 7 ~ "LGBT /social leaders", 
           topic == 8 ~ "Reproductive health",
           topic == 9 ~ "Institutional events", 
           topic == 10 ~ "Public life"))

```  

```{r}
# Plotting all topics at once 
weekly_topics_ins %>%  
  ggplot(aes(x = date,
           y = proportion_topic_week,
           color = factor(topic))) +
  geom_line(alpha = 0.5, size = 0.6) + 
  geom_point() + 
  theme_minimal()+
  labs(title = "Proportion of documents from each topic by week (2020)",
       x = "\n Week published",
       y = "Proportion of documents \n") +
   scale_color_manual(values = c(colors),
                     name = "Topic") +
   ylim(0, 0.4)

```

# Gathering a subset of the tweets that mainly talk about political matters.

```{r}

tweets_on_rephealth <- institutions_wgammas %>% 
  group_by(topic) %>% 
  filter(gamma > 0.4,
         topic %in% c(8))
save(tweets_on_rephealth, file = "data/ind_tweets_on_rephealth")

```