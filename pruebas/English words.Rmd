---
title: "Exploring data 2.0"
author: "Natalia Mejia"
date: "9/12/2020"
output: html_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(quanteda)
library(readtext) # for getting document and their info into a data frame 
library(tm)
library(lubridate)
library(tidytext)
library(ggplot2)
library(dplyr)
library(wordcloud)
library(stringr)

load("data/tweets_feminists.RData")
names(feminists)

#Subsetting dataset

feminists <- 
  feminists %>% 
  select(name, 
         screen_name, 
         text,
         user_id, 
         created_at, 
         retweet_count,
         main_occupation,
         institution)

#Creating corpus
feminists_corp <- corpus(feminists)


```


```{r}
#Creating dfm

corpdfm <- dfm(feminists_corp)


# Removing unnecessary words; stem the text, extract n-grams, remove punctuation, keep Twitter features

corpdfm <- dfm(feminists_corp, 
             tolower = TRUE, # convert all words to lower case 
             stem = TRUE, 
             remove = c(stopwords("spanish")),
             remove_punct = TRUE, # remove punctuation
             remove_url = TRUE, # remove u
             remove_numbers = TRUE,
             remove_symbols = TRUE,
             verbose = TRUE) 
             
# Remove mentions (@)
corpdfm <- dfm_remove(corpdfm,
                      "@*",
                      verbose = T)

#Remove hashtags         
corpdfm <- dfm_remove(corpdfm,
                      "#*",
                      verbose = T)

# Remove more stopwords (less than 4 characters)
corpdfm <- dfm_keep(corpdfm,
                    min_nchar = 4,
                      verbose = T)

#Remove stopwords in english


corpdfm <- dfm_remove(corpdfm,
                        stopwords(kind = quanteda_options("language_stopwords")),
                                  verbose = T)

```

# Get data and clean it. Create dfm. 
```{r}

# Load data with tweets from individual (not congresswomen) feminists' twitter accounts between july and november 2020. 

load("data/pruebas/non_congress_fem_jul_nov_2020.RData")

non_congress <- non_congress_fem_jul_nov_2020

non_congress <- 
  non_congress %>% 
  select(name, 
         screen_name, 
         text,
         user_id, 
         created_at, 
         retweet_count,
         main_occupation,
         institution)

# Remove accounts that do not talk about gender much
non_congress <- filter(non_congress, name != c("Rodrigo Sandoval", "Sara Tufano", "Juan Carlos Rincón Escalante"))

#Creating corpus
non_congress_corp <- corpus(non_congress)

# Removing unnecessary words; stem the text, extract n-grams, remove punctuation, keep Twitter features…
non_congress_dfm <- dfm(non_congress_corp, 
             tolower = TRUE, # convert all words to lower case 
             remove = c(stopwords("spanish")),
             remove_punct = TRUE, # remove punctuation
             remove_url = TRUE, # remove u
             remove_numbers = TRUE,
             remove_symbols = TRUE,
             verbose = TRUE) # Bueno hacer esta opción para ver que está haciendo el dfm.
            #it is better not to stem for topic models  
             
# Remove mentions (@)
non_congress_dfm <- dfm_remove(non_congress_dfm,
                      "@*",
                      verbose = T)

#Remove hashtags         
non_congress_dfm <- dfm_remove(non_congress_dfm,
                      "#*",
                      verbose = T)

# Remove more stopwords (less than 4 characters)
non_congress_dfm <- dfm_keep(non_congress_dfm,
                    min_nchar = 4,
                      verbose = T)

# Remove additional words that do not do meaningful work 
load("additional_stopwords.RData")

non_congress_dfm <- dfm_remove(non_congress_dfm,
                    additional_stopowrds,
                      verbose = T)

#Creating a random sample of 7000 tweets to test the topic model (full dfm is too large)
sample_non_congress <- dfm_sample(x = non_congress_dfm, size = 7000, margin = "documents")

```

```{r}
#Running the structural topic model

#Make the quanteda dfm a stm corpus for running the model
stm_sample_non_congress <- asSTMCorpus(sample_non_congress)

# Getting info from the corpus
out <- prepDocuments(stm_sample_non_congress$documents, 
                     stm_sample_non_congress$vocab, 
                     stm_sample_non_congress$meta)

# Running the structural topic model, defining 10 topics. 
model_topics_non_congress <- stm(documents = out$documents, 
              vocab = out$vocab, 
              K = 10, seed = 12345)

```

```{r}
stm_sample_non_congress <- asSTMCorpus(sample_non_congress)

# Getting info from the corpus
out <- prepDocuments(stm_sample_non_congress$documents, 
                     stm_sample_non_congress$vocab, 
                     stm_sample_non_congress$meta)

model_topics_non_congress <- stm(documents = out$documents, 
              vocab = out$vocab, 
              K = 10, seed = 12345)

labelTopics(model_topics_non_congress)

```
```{r}

cloud_mod79 <- cloud(model_topics_non_congress, topic = 5, type = c("model")) 
```

```{r}
#The tidytext package provides this method for extracting the per-topic-per-word probabilities, called β (“beta”)

model_topics <- tidy(model_topics_non_congress, matrix = "beta")
model_topics

model_top_terms <- model_topics %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

#Identify the words that are most common within topics

model_top_terms %>% 
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()

```



```{r}
#Create dictionary based on most used words per topic

dic_words <- dictionary(list(feminism = c("derechos", "violencia", "sexual", "gobierno", "mujeres", "marchas", "hombres", "acuerdo", "politica", "guerra", "feminista", "feminismo", "vida", "policia", "trans", "victimas", "polarizacion", "genero", "justicia", "elites", "colombia", "democracia", "decision", "mujer", "cuerpo", "poder")))


#Filtering dfm with dictionary

subset_corpdfm <- dfm_select(corpdfm, pattern = dic_words)

```


